---
title: "EP 960 Issues of non-normality"
author: "David Kaplan"
output:
  html_document: default
pdf_document: default

---
# Install relevant packages

install.packages("lavaan")

install.packages("semTools")

install.packages("MVN")

install.packages("mice")
```{r,echo=TRUE}
library(lavaan)
library(semTools)
library(MVN)
library(mice)
```
```{r,echo=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

# Read in data
```{r,echo=TRUE}
burnout <- read.csv("~/desktop/TeachBurnout.csv",header=T)
```

# Assessing univariate and multivariate normality

```{r,echo=TRUE}
mvntest <- mvn(burnout,mvnTest="mardia",univariateTest="Lillie")
mvntest
```

We see also that the data are not multivariate normal either.  This is not at all surprising, given that the data are skewed and categorical.



## Multiple methods for handling non-normality ##

```{r,echo=TRUE}
burnoutCFA.model <- ' TSC =~ TSC1+TSC2+TSC3+TSC4+TSC5          
                      TE  =~ TE1+TE2+TE3+TE4+TE4
                      EE  =~ EE1+EE2+EE3+EE4+EE5
                      DE  =~ DE1+DE2+DE3
                      RPA =~ RPA1+RPA2+RPA3+RPA4+RPA5'
```

### Maximum likelihood
```{r,echo=TRUE}
fitml <- sem(burnoutCFA.model,data=burnout,estimator="ml")
summary(fitml, fit.measures=TRUE)
```

### Robust ML
```{r,echo=TRUE}
fitmlr <- sem(burnoutCFA.model,data=burnout,estimator="mlr")
summary(fitmlr, fit.measures=TRUE)
```

### Weighted least squares
```{r,echo=TRUE}
fitwls <- sem(burnoutCFA.model,data=burnout,estimator="wls")
summary(fitwls, fit.measures=TRUE)
```

### Weighted least squares with mean and variance adjustment
```{r,echo=TRUE}
fitwlsmv <- sem(burnoutCFA.model,data=burnout,estimator="wlsmv")
summary(fitwlsmv, fit.measures=TRUE)
```

This section uses "mlr", "wls", and "wlsmv", but all of these methods assume continuous data and does not directly treat the categorical nature of the data.  Note that we do see some differences, particularly improvement with "mlr" and "wlsmv".  Keep in mind that in this example there is no missing data.



